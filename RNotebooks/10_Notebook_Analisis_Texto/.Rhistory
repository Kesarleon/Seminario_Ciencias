}
View(prices_out)
prices_out<-NULL
for (i in seq(1, length(tickers))){
print(i)
prices<-getSymbols(tickers[i] ,auto.assign=FALSE)
colnames(prices)<- c('Open','High', 'Low', 'Close', 'Volume', 'Adjusted')
prices<- as.data.frame(prices)
prices$dates<- row.names(prices)
prices$ticker<- tickers[i]
row.names(prices)<- NULL
if (i>10){
break
}
prices_out<- rbind(prices_out, prices)
}
View(prices_out)
prices_out<-NULL
for (i in seq(1, length(tickers))){
print(i)
prices<-getSymbols(tickers[i] ,auto.assign=FALSE)
colnames(prices)<- c('Open','High', 'Low', 'Close', 'Volume', 'Adjusted')
prices<- as.data.frame(prices)
prices$dates<- row.names(prices)
prices$ticker<- tickers[i]
row.names(prices)<- NULL
prices_out<- rbind(prices_out, prices)
}
save(prices_out, '/Users/alimon/Documents/dataset/prices_nms-nyq.RData')
save(prices_out, file='/Users/alimon/Documents/dataset/quantmod/prices_nms-nyq.RData')
knitr::opts_chunk$set(echo = TRUE)
#### Para incluir un quote mark
string2<- "\""
string2
#### Para incluir un quote mark
string2<- '""
string2
#### Para incluir un quote mark
string2<- '"'
string2
#### Para incluir un quote mark
string2<- '"'
#### Para incluir un quote mark
string2<- '"'
#### Para incluir un quote mark
string2<- '"'
#### Para incluir un quote mark
string2<- '"quetal'
### La representacion printed de un string no es lo mismo que el mismo string
writeLines(c("\"", "\\"))
c("\"", "\\")
print(c("\"", "\\"))
### Existen caracteres especiales que pueden ser muy utiles por ejemplo:
string1<- "ciencia de datos \n finanzas \n convergen"
writeLines(string1)
string1<- "ciencia de datos finanzas convergen"
writeLines(string1)
?'"'
### Multiples strings pueden ser almacenados en un vector character
c("one", "two", "three")
### Para obtener la longitud de un string
str_length(c("a", "R for data science", NA))
suppressMessages(library(stringr))
### Para obtener la longitud de un string
str_length(c("a", "R for data science", NA))
### Para combinar strings
str_c("x", "y", "z")
paste0("x", "y", "z")
paste("x", "y", "z", sep='.')
str_c("x", "y", sep = ".")
### Para colapsar un arreglo a un string
str_c(c("x", "y", "z"), collapse = ", ")
### Subset un string
x <- c("Apple", "Banana", "Pear")
str_sub(x, 1, 3)
#
str_to_lower("TODAS EN MAYUSCULA")
### Pasar a mayusculas
str_to_upper("todas minusculas")
### Pasar a mayusculas
str_to_upper("todas en mayuscula")
### Pasar a minusculas
str_to_lower("TODAS EN minuscula")
### Pasar a mayusculas
str_to_upper("todas en mayuscula")
x <- c("apple", "banana", "pear")
str_view(x, "an")
library(htmlwidgets)
install.packages("htmlwidgets")
library(htmlwidgets)
x <- c("apple", "banana", "pear")
str_view(x, "an")
suppressMessages(library(htmlwidgets))
x <- c("apple", "banana", "pear")
str_view(x, "an")
### Encontrar patrones que empaten con strings exactos
x <- c("apple", "banana", "pear")
str_view(x, "an")
### ncontrar patrones que empaten con strings exactos mas un caracter
str_view(x, ".a.")
#### Caso especial
#Para incluir un quote mark
double_quote <- "\"" # or '"'
double_quote
double_quote
single_quote <- '\''
single_quote
### La representacion printed de un string no es lo mismo que el mismo string
writeLines(c("\"", "\\"))
print(c("\"", "\\"))
### Para obtener la longitud de un string
str_length(c("a", "R para ciencia de datos", NA))
### 7.2) Combinar strings
str_c("x", "y", "z")
str_c("x", "y", sep = ".")
paste0("x", "y", "z")
paste("x", "y", "z", sep='.')
### Para colapsar un arreglo a un string
str_c(c("x", "y", "z"), collapse = ", ")
### 7.2) Colapsar lista de strings en un solo string
str_c("x", "y", "z")
str_c("x", "y", sep = ".")
paste0("x", "y", "z")
paste("x", "y", "z", sep='.')
### 7.3) Tomar subconjuntos de string
x <- c("Bono", "Derivado", "Accion")
str_sub(x, 1, 3)
### 7.4) Pasar a minusculas un string
str_to_lower("CIENCIA DE DATOS")
knitr::opts_chunk$set(echo = TRUE)
company_desc<- read.csv('dataset/dataset_comp_descr.csv')
head(company_desc)
head(company_desc,1)
company_industry<- read.csv('dataset/dataset_comp_industry.csv')
suppressMessages(library(dbplyr))
dataset_company<- left_join(company_desc, company_industry, by='comp_id' )
suppressMessages(library(dbplyr))
dataset_company<- left_join(company_desc, company_industry, by='comp_id' )
suppressMessages(library(dplyr))
dataset_company<- left_join(company_desc, company_industry, by='comp_id' )
View(dataset_company)
head(dataset_company, 1)
suppressMessages(library(tidytext))
suppressMessages(library(tidytext))
dataset_token<- dataset_company %>% unnest_tokens(word, LongBusinessSummary)
View(dataset_company)
dataset_token<- dataset_company %>% unnest_tokens(word, LongBusinessSummary)
dataset_company$LongBusinessSummary<- as.character(dataset_company$LongBusinessSummary)
dataset_token<- dataset_company %>% unnest_tokens(word, LongBusinessSummary)
View(dataset_token)
View(company_desc)
View(dataset_token)
View(dataset_company)
data(stop_words)
dataset_token <- dataset_token %>%
anti_join(dataset_token)
dataset_token<- dataset_company %>% unnest_tokens(word, LongBusinessSummary)
dataset_token <- dataset_token %>%
anti_join(stop_words)
View(dataset_token)
dataset_token <- dataset_token %>%
filter(!word %in% stop_words)
dataset_token<- dataset_company %>% unnest_tokens(word, LongBusinessSummary)
dataset_token<- dataset_company %>% unnest_tokens(word, LongBusinessSummary)
print(paste0('El numero de renglones del dataset con stopwords es:',length(dataset_token )))
print(paste0('El numero de renglones del dataset con stopwords es:',nrows(dataset_token)))
print(paste0('El numero de renglones del dataset con stopwords es:',nrow(dataset_token)))
dataset_token <- dataset_token %>%
filter(!word %in% stop_words)
print(paste0('El numero de renglones del dataset sin stopwords es:',nrow(dataset_token )))
dataset_token <- dataset_token %>%
filter(!word %in% stop_words)
dataset_token <- filter(dataset_token, !word %in% stop_words)
stop_words
dataset_token <- filter(dataset_token, !word %in% stop_words$word)
print(paste0('El numero de renglones del dataset sin stopwords es:',nrow(dataset_token )))
suppressMessage(library(ggplot2))
suppressMessages(library(ggplot2))
dataset_token %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
dataset_token %>%
count(word, sort = TRUE) %>%
filter(n > 10000) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
dataset_token %>%
count(word, sort = TRUE) %>%
filter(n > 80000) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
dataset_token %>%
count(word, sort = TRUE) %>%
filter(n > 80000) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
dataset_token %>%
count(word, sort = TRUE) %>%
filter(n > 90000) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
dataset_token %>%
count(word, sort = TRUE) %>%
filter(n > 100000) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
dataset_token %>%
count(word, sort = TRUE) %>%
filter(n > 10000) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
dataset_token %>%
count(word, sort = TRUE) %>%
filter(n > 9000) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
dataset_token %>%
count(word, sort = TRUE) %>%
filter(n > 5000) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
View(dataset_token)
View(dataset_token)
dataset_company %>% count(Sector, sort = TRUE)
dataset_token_financial<- filter(dataset_token, Sector='Industrials')
dataset_token_ind<- filter(dataset_token, Sector=='Industrials')
dataset_token_fin<- filter(dataset_token, Sector=='Financial Services')
dataset_token_con<- filter(dataset_token, Sector=='Consumer Cyclical')
dataset_token_tech<- filter(dataset_token, Sector=='Technology')
dataset_token_sector<- dataset_token %>% count(author, word) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
dataset_token_sector<- dataset_token %>% count(Sector, word) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
View(dataset_token_sector)
dataset_token <- filter(dataset_token, !word %in% stop_words$word & !is.digit(word))
dataset_token<- dataset_company %>% unnest_tokens( "characters", LongBusinessSummary)
View(dataset_token)
dataset_token <- filter(dataset_token, !word %in% stop_words$word)
dataset_token <- filter(dataset_token, !characters %in% stop_words$word)
dataset_token_sector<- dataset_token %>% count(Sector, word) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
dataset_token_sector<- dataset_token %>% count(Sector, characters) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
View(dataset_token_sector)
a<-dataset_token %>%
filter(str_detect(characters, "\\d"))
library(stringr)
a<-dataset_token %>%
filter(str_detect(characters, "\\d"))
View(a)
dataset_token<- dataset_company %>% unnest_tokens( words, LongBusinessSummary)
dataset_token <- filter(dataset_token, !word %in% stop_words$word & !str_detect(characters, "\\d"))
dataset_token <- filter(dataset_token, !word %in% stop_words$word & !str_detect(words, "\\d"))
dataset_token <- filter(dataset_token, !word %in% stop_words$word)
dataset_token<- dataset_company %>% unnest_tokens( word, LongBusinessSummary)
dataset_token <- filter(dataset_token, !word %in% stop_words$word)
dataset_token <-  filter(dataset_token, str_detect(word, "\\d"))
dataset_token<- dataset_company %>% unnest_tokens( word, LongBusinessSummary)
dataset_token <- filter(dataset_token, !word %in% stop_words$word)
dataset_token <-  filter(dataset_token, !str_detect(word, "\\d"))
print(paste0('El numero de renglones del dataset sin stopwords es: ',nrow(dataset_token )))
dataset_token_sector<- dataset_token %>% count(Sector, word) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
View(dataset_token_sector)
View(dataset_token_sector)
dataset_token_sector<- dataset_token %>% filter(Sector %in% c('Industrials', 'Financial', 'Consumer', 'Technology')) %>% count(Sector, word) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
View(dataset_token_sector)
View(dataset_token_sector)
library(wordcloud)
install.packages("wordcloud")
set.seed(100)
dataset_token_tech<- filter(dataset_token_sector, Sector=='Technology')
dataset_token_tech$Sector<- NULL
wordcloud(names(dataset_token_tech), dataset_token_tech, min.freq=100
)
library(wordcloud)
wordcloud(names(dataset_token_tech), dataset_token_tech, min.freq=100
)
plot_sector <- dataset_token_sector %>%
arrange(desc(proportion)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
View(plot_sector)
View(plot_sector)
View(dataset_token_sector)
plot_authors %>%
group_by(Sector) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, proportion, fill = Sector)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "Proportion") +
facet_wrap(~Sector, ncol = 3, scales = "free") +
coord_flip()
plot_sector %>%
group_by(Sector) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, proportion, fill = Sector)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "Proportion") +
facet_wrap(~Sector, ncol = 3, scales = "free") +
coord_flip()
plot_sector <- dataset_token_sector %>%
arrange(desc(proportion)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
plot_sector <- dataset_token_sector %>%
arrange(desc(proportion))
View(plot_sector)
plot_sector %>%
group_by(Sector) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, proportion, fill = Sector)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "Proportion") +
facet_wrap(~Sector, ncol = 3, scales = "free") +
coord_flip()
plot_sector <- dataset_token_sector %>%
arrange(desc(proportion))
plot_sector %>%
group_by(Sector) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, proportion, fill = Sector)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "Proportion") +
facet_wrap(~Sector, ncol = 3, scales = "free") +
coord_flip()
plot_sector <- dataset_token_sector %>%
arrange(proportion)
plot_sector %>%
group_by(Sector) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, proportion, fill = Sector)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "Proportion") +
facet_wrap(~Sector, ncol = 3, scales = "free") +
coord_flip()
plot_sector %>%
group_by(Sector) %>%
top_n(20) %>%
ungroup %>%
ggplot(aes(word, proportion, fill = Sector)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "Proportion") +
facet_wrap(~Sector, ncol = 3, scales = "free") +
coord_flip()
View(plot_sector)
plot_sector <- dataset_token_sector %>%
arrange(desc(proportion))
plot_sector %>%
group_by(Sector) %>%
top_n(20) %>%
ungroup %>%
ggplot(aes(word, proportion, fill = Sector)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "Proportion") +
facet_wrap(~Sector, ncol = 3, scales = "free") +
coord_flip()
plot_sector <- dataset_token_sector %>%
arrange(desc(proportion)) %>%  mutate(word = factor(word, levels = rev(unique(word))))
plot_sector %>%
group_by(Sector) %>%
top_n(20) %>%
ungroup %>%
ggplot(aes(word, proportion, fill = Sector)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "Proportion") +
facet_wrap(~Sector, ncol = 3, scales = "free") +
coord_flip()
dataset_token_sector$word<- as.character(dataset_token_sector$word)
plot_sector <- dataset_token_sector %>%
arrange(desc(proportion)) %>%  mutate(word = factor(word, levels = rev(unique(word))))
dataset_token_sector$word<- factor(as.character(dataset_token_sector$word),  levels = rev(unique(word)))
dataset_token_sector$word<- factor(as.character(dataset_token_sector$word),  levels = rev(unique(dataset_token_sector$word)))
View(dataset_token_sector)
plot_sector <- dataset_token_sector %>%
arrange(desc(proportion))
plot_sector %>%
group_by(Sector) %>%
top_n(20) %>%
ungroup %>%
ggplot(aes(word, proportion, fill = Sector)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "Proportion") +
facet_wrap(~Sector, ncol = 3, scales = "free") +
coord_flip()
plot_sector <- dataset_token_sector %>%
arrange(desc(proportion))
plot_sector %>%
group_by(Sector) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, proportion, fill = Sector)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "Proportion") +
facet_wrap(~Sector, ncol = 3, scales = "free") +
coord_flip()
plot_sector <- dataset_token_sector %>%
arrange(proportion)
plot_sector %>%
group_by(Sector) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, proportion, fill = Sector)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "Proportion") +
facet_wrap(~Sector, ncol = 3, scales = "free") +
coord_flip()
View(plot_sector)
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, min.freq = 100,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
dataset_token_sector<- dataset_token %>% filter(Sector %in% c('Industrials')) %>% count(Sector, word) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, min.freq = 100,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
View(dataset_token_sector)
View(dataset_token_sector)
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, min.freq = 100, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, min.freq = 100, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"), scale=c(4,.5))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, min.freq = 100, max.words = 30,random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"), scale=c(4,.2))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, min.freq = 100, max.words = 30,random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"), scale=c(4,.1))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, max.words = 25,random.order=FALSE, scale=c(4,.1))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, max.words = 25,random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2"), scale=c(4,.1))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, max.words = 25,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.1))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, max.words = 25,random.order=FALSE, scale=c(4,.1))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, max.words = 20,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.1))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, max.words = 40,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.1))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, max.words = 40,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.01))
wordcloud(words = dataset_token_sector$word, freq = dataset_token_sector$n, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.01))
dataset_token_ind<- dataset_token %>% filter(Sector=='Industrials') %>% count(Sector, word) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
wordcloud(words = dataset_token_ind$word, freq = dataset_token_ind$n, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.01))
dataset_token_ind<- dataset_token %>% filter(Sector=='Industrials') %>% count(Sector, word) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
View(dataset_token_ind)
wordcloud(words = dataset_token_ind$word, freq = dataset_token_ind$n, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.01))
wordcloud(words = dataset_token_fin$word, freq = dataset_token_fin$n, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.01))
dataset_token_fin<- dataset_token %>% filter(Sector=='Financials') %>% count(Sector, word) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
View(dataset_token)
dataset_token_fin<- dataset_token %>% filter(Sector=='Financial Services') %>% count(Sector, word) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
wordcloud(words = dataset_token_fin$word, freq = dataset_token_fin$n, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.01))
dataset_token_tech<- dataset_token %>% filter(Sector=='Technology') %>% count(Sector, word) %>% group_by(Sector) %>%
mutate(proportion = n / sum(n))
dataset_token_tfidf <- dataset_token %>%
bind_tf_idf(word, Sector, n)
View(dataset_token)
dataset_token_sector<- dataset_token %>% count(Sector, word) %>% group_by(Sector)
dataset_token_tfidf <- dataset_token_sector %>%
bind_tf_idf(word, Sector, n)
View(dataset_token_tfidf)
dataset_token_ind<- dataset_token_tfidf %>% filter(Sector=='Industrials')
dataset_token_fin<- dataset_token_tfidf %>% filter(Sector=='Financial Services')
dataset_token_tech<- dataset_token_tfidf %>% filter(Sector=='Technology')
wordcloud(words = dataset_token_ind$word, freq = dataset_token_ind$n, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.01))
wordcloud(words = dataset_token_ind$word, freq = dataset_token_ind$tf_idf, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.01))
wordcloud(words = dataset_token_ind$word, freq = dataset_token_ind$tf_idf, max.words = 50,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.01))
wordcloud(words = dataset_token_fin$word, freq = dataset_token_fin$tf_idf, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.01))
wordcloud(words = dataset_token_fin$word, freq = dataset_token_fin$tf_idf, max.words = 50,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(4,.001))
wordcloud(words = dataset_token_fin$word, freq = dataset_token_fin$tf_idf, max.words = 50,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(3,.001))
wordcloud(words = dataset_token_fin$word, freq = dataset_token_fin$tf_idf, max.words = 50,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(3,.01))
wordcloud(words = dataset_token_fin$word, freq = dataset_token_fin$tf_idf, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(3,.01))
wordcloud(words = dataset_token_ind$word, freq = dataset_token_ind$tf_idf, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"),scale=c(3,.01))
wordcloud(words = dataset_token_ind$word, freq = dataset_token_ind$tf_idf, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"),scale=c(2,.01))
wordcloud(words = dataset_token_fin$word, freq = dataset_token_fin$tf_idf, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(2,.01))
View(dataset_token_tfidf)
View(company_desc)
wordcloud(words = dataset_token_tech$word, freq = dataset_token_tech$tf_idf, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"),scale=c(3,.01))
wordcloud(words = dataset_token_tech$word, freq = dataset_token_tech$tf_idf, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"),scale=c(2,.01))
wordcloud(words = dataset_token_fin$word, freq = dataset_token_fin$tf_idf, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"), scale=c(2,.01))
wordcloud(words = dataset_token_ind$word, freq = dataset_token_ind$tf_idf, max.words = 100,random.order=FALSE, colors=brewer.pal(8, "Dark2"),scale=c(2,.01))
View(dataset_token_sector)
View(dataset_token_tech)
View(dataset_token)
